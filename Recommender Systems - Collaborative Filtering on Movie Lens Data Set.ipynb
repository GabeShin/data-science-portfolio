{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________\n",
    "# Recommender Systems - Movie Lens Data\n",
    "_______\n",
    "\n",
    "Hello! \n",
    "\n",
    "In this notebook, I will use two methods if **Collaborative Filtering** to recommend movies to the users.\n",
    "- Memory-Based Collaborative Filtering by computing cosine similarity\n",
    "- Model-Based Collaborative Filtering by using singular value decomposition (SVD)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data\n",
    "_____\n",
    "\n",
    "We will use MovieLens dataset. It contains 100k movie ratings from 943 users and a selection of 1682 movies.\n",
    "\n",
    "The dataset is available [here](http://files.grouplens.org/datasets/movielens/ml-100k.zip).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the data in the **u.data** file, which contains the full dataset. \n",
    "\n",
    "A brief description of the dataset is [here](http://files.grouplens.org/datasets/movielens/ml-100k-README.txt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>5</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>133</td>\n",
       "      <td>1</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "0        0       50       5  881250949\n",
       "1        0      172       5  881250949\n",
       "2        0      133       1  881250949\n",
       "3      196      242       3  881250949\n",
       "4      186      302       3  891717742"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "\n",
    "#  it's tab serparated file\n",
    "df = pd.read_csv('input/u.data', sep='\\t', names=column_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a seperate 'Movie_Id_Title' csv file. Se will merge movie titles to the item_id so it's more than just meaningless numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>881250949</td>\n",
       "      <td>Star Wars (1977)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>290</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>880473582</td>\n",
       "      <td>Star Wars (1977)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>79</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>891271545</td>\n",
       "      <td>Star Wars (1977)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>888552084</td>\n",
       "      <td>Star Wars (1977)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>879362124</td>\n",
       "      <td>Star Wars (1977)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp             title\n",
       "0        0       50       5  881250949  Star Wars (1977)\n",
       "1      290       50       5  880473582  Star Wars (1977)\n",
       "2       79       50       4  891271545  Star Wars (1977)\n",
       "3        2       50       5  888552084  Star Wars (1977)\n",
       "4        8       50       5  879362124  Star Wars (1977)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_titles = pd.read_csv(\"input/Movie_Id_Titles\")\n",
    "df = pd.merge(df,movie_titles,on='item_id')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "________\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How many unique number of movies and users in the data?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. of Users: 944\n",
      "Num of Movies: 1682\n"
     ]
    }
   ],
   "source": [
    "n_users = df.user_id.nunique()\n",
    "n_items = df.item_id.nunique()\n",
    "\n",
    "print('Num. of Users: '+ str(n_users))\n",
    "print('Num of Movies: '+str(n_items))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Movies with the highest average ratings **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title\n",
       "Marlene Dietrich: Shadow and Light (1996)     5.0\n",
       "Prefontaine (1997)                            5.0\n",
       "Santa with Muscles (1996)                     5.0\n",
       "Star Kid (1997)                               5.0\n",
       "Someone Else's America (1995)                 5.0\n",
       "Name: rating, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('title')['rating'].mean().sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Movies with the most number of ratings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title\n",
       "Star Wars (1977)             584\n",
       "Contact (1997)               509\n",
       "Fargo (1996)                 508\n",
       "Return of the Jedi (1983)    507\n",
       "Liar Liar (1997)             485\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('title')['rating'].count().sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Never seen those movies with the highest ratings!\n",
    "\n",
    "Let's look more into the relationship between ratings and number of ratings by ** creating a new dataframe with average rating and number of ratings per movies.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>num of ratings</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>'Til There Was You (1997)</th>\n",
       "      <td>2.333333</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1-900 (1994)</th>\n",
       "      <td>2.600000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101 Dalmatians (1996)</th>\n",
       "      <td>2.908257</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12 Angry Men (1957)</th>\n",
       "      <td>4.344000</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187 (1997)</th>\n",
       "      <td>3.024390</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             rating  num of ratings\n",
       "title                                              \n",
       "'Til There Was You (1997)  2.333333               9\n",
       "1-900 (1994)               2.600000               5\n",
       "101 Dalmatians (1996)      2.908257             109\n",
       "12 Angry Men (1957)        4.344000             125\n",
       "187 (1997)                 3.024390              41"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = pd.DataFrame(df.groupby('title')['rating'].mean())\n",
    "ratings['num of ratings'] = pd.DataFrame(df.groupby('title')['rating'].count())\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x14cdc770ac8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "ratings['num of ratings'].hist(bins=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x14cdcb38828>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "ratings['rating'].hist(bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obeservations \n",
    "- There are a lot of movies that has only few number of ratings.\n",
    "- There are concentrations of movies with ratings 1, 2, 3, 4. Probably because of how movie rating systems are designed (can only pick whole number) and great number of movies with only few numbers of ratings.\n",
    "- We will need to decide on the minimum number of ratings required for the movie for model building. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split\n",
    "___________\n",
    "\n",
    "We will split the data into two sets for training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data, test_data = train_test_split(df, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory-Based Collaborative Filtering Model\n",
    "____\n",
    "\n",
    "Movie recommendation approach can be divided into two main sections: **user-item filtering** and **item-item filtering**. \n",
    "\n",
    "A *user-item filtering* will take a particular user, find users that are similar to that user based on similarity of ratings, and recommend items that those similar users liked. \n",
    "\n",
    "In contrast, *item-item filtering* will take an item, find users who liked that item, and find other items that those users or similar users also liked. It takes items and outputs other items as recommendations. \n",
    "\n",
    "* *Item-Item Collaborative Filtering*: “Users who liked this item also liked …”\n",
    "* *User-Item Collaborative Filtering*: “Users who are similar to you also liked …”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For *Item-Item Collaborative Filtering* the similarity between items are measured by **observing all the users who have rated both items.**\n",
    "\n",
    "\n",
    "For *User-Item Collaborative Filtering* the similarity values between users are measured by **observing all the items that are rated by both users.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A distance metric commonly used in recommender systems is *cosine similarity*, where the ratings are seen as vectors in ``n``-dimensional space and the similarity is calculated based on the angle between these vectors. \n",
    "\n",
    "We will use Scikit-Learn libraries to calculate the cosine similarity. \n",
    "\n",
    "First, let's **create the user-item matrix for both testing and training data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create two user-item matrices for training and another for testing\n",
    "train_data_matrix = np.zeros((n_users, n_items))\n",
    "for line in train_data.itertuples():\n",
    "    train_data_matrix[line[1]-1, line[2]-1] = line[3]  \n",
    "\n",
    "#Create two user-item matrices for testing\n",
    "test_data_matrix = np.zeros((n_users, n_items))\n",
    "for line in test_data.itertuples():\n",
    "    test_data_matrix[line[1]-1, line[2]-1] = line[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculated the cosine similarity using the [pairwise_distances](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.pairwise_distances.html).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "user_similarity = pairwise_distances(train_data_matrix, metric='cosine')\n",
    "item_similarity = pairwise_distances(train_data_matrix.T, metric='cosine')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step is to make predictions. You have already created similarity matrices: `user_similarity` and `item_similarity` and therefore you can make a prediction by applying following formula for user-based CF:\n",
    "\n",
    "<img class=\"aligncenter size-thumbnail img-responsive\" src=\"https://latex.codecogs.com/gif.latex?\\hat{x}_{k,m}&space;=&space;\\bar{x}_{k}&space;&plus;&space;\\frac{\\sum\\limits_{u_a}&space;sim_u(u_k,&space;u_a)&space;(x_{a,m}&space;-&space;\\bar{x_{u_a}})}{\\sum\\limits_{u_a}|sim_u(u_k,&space;u_a)|}\"/>\n",
    "\n",
    "You can look at the similarity between users *k* and *a* as weights that are multiplied by the ratings of a similar user *a* (corrected for the average rating of that user). You will need to normalize it so that the ratings stay between 1 and 5 and, as a final step, sum the average ratings for the user that you are trying to predict. \n",
    "\n",
    "The idea here is that some users may tend always to give high or low ratings to all movies. The relative difference in the ratings that these users give is more important than the absolute values. To give an example: suppose, user *k* gives 4 stars to his favourite movies and 3 stars to all other good movies. Suppose now that another user *t* rates movies that he/she likes with 5 stars, and the movies he/she fell asleep over with 3 stars. These two users could have a very similar taste but treat the rating system differently. \n",
    "\n",
    "When making a prediction for item-based CF you don't need to correct for users average rating since query user itself is used to do predictions.\n",
    "\n",
    "<img class=\"aligncenter size-thumbnail img-responsive\" src=\"https://latex.codecogs.com/gif.latex?\\hat{x}_{k,m}&space;=&space;\\frac{\\sum\\limits_{i_b}&space;sim_i(i_m,&space;i_b)&space;(x_{k,b})&space;}{\\sum\\limits_{i_b}|sim_i(i_m,&space;i_b)|}\"/>\n",
    "\n",
    "Now let's make predictions. There are few things to keep in mind while making predictions: \n",
    "- We will need to normalize the prediction so that the ratings can stay between 1 and 5.\n",
    "- Relative difference in the rating (for each user) is more important than the absolute values, because some users may tend always to give high or low rating to all movies. So when making a prediction **for user-based CF, we will want to correct for users average rating. **\n",
    "- BUT when we are making predition **for item-based CF, we don't need to, because query user itself is used to do the prediction.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(ratings, similarity, type='user'):\n",
    "    if type == 'user':\n",
    "        mean_user_rating = ratings.mean(axis=1)\n",
    "        #You use np.newaxis so that mean_user_rating has same format as ratings\n",
    "        ratings_diff = (ratings - mean_user_rating[:, np.newaxis]) \n",
    "        pred = mean_user_rating[:, np.newaxis] + similarity.dot(ratings_diff) / np.array([np.abs(similarity).sum(axis=1)]).T\n",
    "    elif type == 'item':\n",
    "        pred = ratings.dot(similarity) / np.array([np.abs(similarity).sum(axis=1)])     \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_prediction = predict(train_data_matrix, item_similarity, type='item')\n",
    "user_prediction = predict(train_data_matrix, user_similarity, type='user')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of the Memory-Based CF\n",
    "\n",
    "We will evaluate the accuracy of prediction by using **Root Mean Squared Error (RMSE)**\n",
    "\n",
    "And also, since we only want to consider predicted ratings that are in the test dataset, we will filter out all other elements in the prediction matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "def rmse(prediction, ground_truth):\n",
    "    # ground_truth.nonzero() used to filter out other elements\n",
    "    prediction = prediction[ground_truth.nonzero()].flatten() \n",
    "    ground_truth = ground_truth[ground_truth.nonzero()].flatten()\n",
    "    return sqrt(mean_squared_error(prediction, ground_truth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-based CF RMSE: 3.1583709896106478\n",
      "Item-based CF RMSE: 3.4666191253751624\n"
     ]
    }
   ],
   "source": [
    "print('User-based CF RMSE: ' + str(rmse(user_prediction, test_data_matrix)))\n",
    "print('Item-based CF RMSE: ' + str(rmse(item_prediction, test_data_matrix)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Welp, doesn't look too good! But it's okay. \n",
    "\n",
    "Drawback of Memory-Based CF is that it doesn't address the cold-start problem and it doesn't scale well to real-world scenarios. \n",
    "\n",
    "While cold-start problem is difficult to address, Model-Based CF Methods are scalable and can deal with higher sparsity level than Memory-Based CF Methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model-based Collaborative Filtering\n",
    "_____________\n",
    "### Understanding Model-based CF\n",
    "Model-based Collaborative Filtering is based on **matrix factorization (MF)**.\n",
    "\n",
    "Matrix factorization is widely used for recommender systems where it can deal better with scalability and sparsity than Memory-based CF. \n",
    "\n",
    "The goal of matrix factorization is **to learn the latent preferences of users and the latent attributes of items from known ratings**(learn features that describe the characteristics of ratings) to then predict the unknown ratings through the dot product of the latent features of users and items.**\n",
    "\n",
    "When you have a very sparse matrix, with a lot of dimensions, by doing matrix factorization you can restructure the  user-item matrix into low-rank structure, and you can represent the matrix by the multiplication of two low-rank matrices, where the rows contain the latent vector. \n",
    "\n",
    "You fit this matrix to approximate your original matrix, as closely as possible, by multiplying the low-rank matrices together, which fills in the entries missing in the original matrix.\n",
    "\n",
    "Let's calculate the sparsity level of MovieLens dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sparsity of the dataset is 93.7%\n"
     ]
    }
   ],
   "source": [
    "sparsity=round(1.0-len(df)/float(n_users*n_items),3)\n",
    "print('The sparsity of the dataset is ' +  str(sparsity*100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we do have very sparse matrix. \n",
    "\n",
    "Because Model-Based CF model uses data to learn the latent features not present in the data *(such as age, location, gender, directors, etc)*, it requires a lot of data to learn the latent features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD\n",
    "The matrix factorization method we will be using is **Singular Value Decomposition (SVD).**\n",
    "\n",
    "To explain, the general equation can be expressed as follows:\n",
    "<img src=\"https://latex.codecogs.com/gif.latex?X=USV^T\" title=\"X=USV^T\" />\n",
    "\n",
    "\n",
    "Given `m x n` matrix `X`:\n",
    "* *`U`* is an *`(m x r)`*: (rows) user-to-concept similarity matrix\n",
    "* *`S`* is an *`(r x r)`*: (diagonal) strength of each concept\n",
    "* *`V^T`* is an *`(r x n)`*: (columns) movie-to-concept similarity matrix\n",
    "\n",
    "Elements on the diagnoal in *`S`* are known as **singular values** of `X`*. \n",
    "\n",
    "The *`U`* matrix represents the feature vectors corresponding to **the users** in the hidden feature space.\n",
    "\n",
    "The *`V`* matrix represents the feature vectors corresponding to **the items** in the hidden feature space.\n",
    "\n",
    "Now that we kind of understand what SVD does, we can **make a prediction by taking dot product of *`U`*, *`S`* and *`V^T`*.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-based CF MSE: 2.7919375093609764\n"
     ]
    }
   ],
   "source": [
    "import scipy.sparse as sp\n",
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "# get SVD components from train matrix \n",
    "# k is number of singular values and vectors to compute\n",
    "u, s, vt = svds(train_data_matrix, k = 20)\n",
    "\n",
    "# created s_diag_matrix\n",
    "s_diag_matrix=np.diag(s)\n",
    "\n",
    "# get the user-based CF by taking dot product of u,s and vt\n",
    "X_pred = np.dot(np.dot(u, s_diag_matrix), vt)\n",
    "\n",
    "# get RMSE of the prediction for evaluation.\n",
    "print('User-based CF MSE: ' + str(rmse(X_pred, test_data_matrix)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Possible Improvements\n",
    "____\n",
    "#### Hybrid Recommender System\n",
    "As mentioned above, both Collaborative Filtering methods suffer from cold-start problem. However, models that use both ratings and content features are called **Hybrid Recommender Systems** where both Collaborative Filtering and Content-based Models are combined.\n",
    "\n",
    "Hybrid recommender systems usually show higher accuracy than Collaborative Filtering or Content-based Models on their own: they are capable to address the cold-start problem better since if you don't have any ratings for a user or an item you could use the metadata from the user or item to make a prediction. \n",
    "\n",
    "#### Alternative least square and stoachastic gradient descent methods\n",
    "Carelessly addressing only the relatively few known entries is highly prone to overfitting. More recent work minimizes the squared error by applying alternating least square or stochastic gradient descent and uses regularization terms to prevent overfitting.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
